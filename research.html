<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Research</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    html { scroll-behavior: smooth; }

    /* timeline container */
    .timeline {
      position: relative;
      display: flex;
      justify-content: space-between;
      align-items: center;
      width: 100%;
      max-width: 1200px;
      margin: 0 auto;
      padding: 1.5rem 2rem;
    }

    .timeline::before {
      content: '';
      position: absolute;
      top: 50%;
      left: 0;
      width: 100%;
      height: 3px;
      background-color: #003366;
      transform: translateY(-50%);
      z-index: 0;
    }

    .timeline::after {
      content: '';
      position: absolute;
      top: 50%;
      right: -10px;
      width: 0;
      height: 0;
      border-top: 6px solid transparent;
      border-bottom: 6px solid transparent;
      border-left: 10px solid #003366;
      transform: translateY(-50%);
    }

    .timeline a {
      position: relative;
      color: #003366;
      font-weight: 600;
      text-align: center;
      padding: 0 8px;
      z-index: 1;
      background-color: #fefefe;
      transition: color 0.2s ease, transform 0.2s ease;
      white-space: nowrap;
    }

    .timeline a:hover {
      color: #2563eb;
      transform: translateY(-3px);
    }

    .timeline-container {
      overflow-x: auto;
      padding-bottom: 0.5rem;
      border-top: 1px solid #d1d5db;
      border-bottom: 1px solid #d1d5db;
      background-color: #f9fafb;
    }
  </style>
</head>

<body class="bg-[#fefefe] text-gray-800 font-sans">

  <!-- NAVIGATION BAR -->
  <nav class="bg-[#003366] text-white px-8 py-4 flex justify-end gap-8 sticky top-0 shadow-lg">
    <a href="index.html" class="hover:underline">Home</a>
    <a href="research.html" class="hover:underline underline font-semibold">Research</a>
    <a href="music.html" class="hover:underline">Music</a>
    <a href="teaching.html" class="hover:underline">Teaching</a>
    <a href="hiking.html" class="hover:underline">Hiking</a>
  </nav>

  <!-- PAGE TITLE -->
  <div class="text-center mt-16 mb-10">
    <h1 class="text-4xl font-bold text-[#003366]">Research</h1>
  </div>

  <!-- CONNECTED TIMELINE -->
  <div class="timeline-container">
    <div class="timeline">
      <a href="#qtim">Sept 2025<br>QTIM Lab</a>
      <a href="#beaverworks">Aug 2025<br>MIT Beaverworks</a>
      <a href="#stanfordaimi">Jun 2025<br>Stanford AIMI</a>
      <a href="#insight">Jun 2025<br>InSight</a>
      <a href="#metafusion">Apr 2025<br>MetaFusion</a>
      <a href="#mediseeker">2024<br>Mediseeker</a>
      <a href="#tissueoforigin">2023<br>Tissue of Origin</a>
      <a href="#lendmeyourear">2023<br>Lend me your ear</a>
      <a href="#connectfour">2022<br>Connect Four</a>
    </div>
  </div>

  <!-- PROJECT SECTIONS -->
  <div class="max-w-4xl mx-auto px-6 py-10 space-y-20">

    <!-- QTIM LAB -->
    <section id="qtim">
      <h2 class="text-2xl font-bold text-[#003366] mb-2">QTIM Lab Intern (Sept 2025)</h2>
      <ul class="list-disc list-inside space-y-2">
        <li>Research Intern at Quantitative Translational Imaging in Medicine Lab @ CU Denver</li>
        <li><strong>Project 1: AI-based diabetes progression prediction based on continuous glucose monitoring data from wearable sensors</strong>
          <ul class="list-disc list-inside ml-5">
            <li>Our work shows that compared to using HbA1c, which remains the standard for diagnosing diabetes, applying deep learning to continuous glucose monitoring data can provide more accurate detection of diabetes progression from healthy and prediabetic individuals to those managing the disease with oral medication.</li>
          </ul>
        </li>
        <div class="my-4">
          <!-- Replace below src with your actual image -->
          <img src="research_images/qtimproject1.png"
     alt="QTIM Project Image"
     class="rounded-lg shadow-md border border-gray-200 mx-auto w-3/4 md:w-2/3">

        </div>
        <li><strong>Project 2: Multimodal AI-based diabetes progression [TO DO]</strong></li>
      </ul>
    </section>

    <!-- MIT BEAVERWORKS -->
<section id="beaverworks">
  <h2 class="text-2xl font-bold text-[#003366] mb-2">
    MIT Beaver Works Summer Institute Medlytics (July - October 2025)
  </h2>

  <ul class="list-disc list-inside space-y-2">
    <li>
      Selected for MIT BWSI Medlytics summer internship, where we learned about applications of AI and data analysis for medical data.
    </li>
    <li>
      Dysarthria is a motor speech disorder that results in slow and often incomprehensible speech.
      Speech intelligibility significantly impacts communication, leading to barriers in social interactions.
    </li>
    <li>
      We worked in a team of 4 to build a unified AI-based multilingual framework and web app to help dysarthric patients communicate effectively with dysarthria detection,
      severity classification, clean speech generation, speech-to-text conversion, and voice cloning.
    </li>
    <li>
      This work demonstrates a scalable, cross-lingual approach to diagnosing and supporting dysarthric patients.
    </li>
    <li>
      <strong>Accepted for poster presentation to Biomedical Engineering Society Annual Meeting 2025</strong>
    </li>
  </ul>

  <!-- Two poster images side by side -->
  <div class="flex flex-wrap justify-center items-center gap-4 mt-6">
    <img
      src="research_images/dysarthria1.png"
      alt="MIT Beaverworks Poster 1"
      class="rounded-lg shadow-md border border-gray-200 w-full sm:w-[48%] md:w-[45%]"
    >
    <img
      src="research_images/dysarthria2.png"
      alt="MIT Beaverworks Poster 2"
      class="rounded-lg shadow-md border border-gray-200 w-full sm:w-[48%] md:w-[45%]"
    >
  </div>
</section>

 
    <!-- STANFORD AIMI -->
<section id="stanfordaimi">
  <h2 class="text-2xl font-bold text-[#003366] mb-2">
    Stanford AIMI Research Interns (June 2025)
  </h2>

  <ul class="list-disc list-inside space-y-2">
    <li>
      Selected for Stanford Artificial Intelligence in Medical Imaging Summer Research Internship.
    </li>
    <li>
      Explored applications of AI for classification, segmentation, and localization of pneumonia from chest X-rays.
    </li>
    <li>
      At the final symposium, all projects were judged by Stanford faculty and our teams won first and second places.
    </li>
    <li>[poster image]</li>
  </ul>

  <!-- Replace this placeholder once your poster image is ready -->
  <div class="my-4">
    <img src="research_images/stanfordaimi_poster.png"
         alt="Stanford AIMI Poster"
         class="rounded-lg shadow-md border border-gray-200 mx-auto w-3/4 md:w-2/3">
  </div>
</section>


   <!-- INSIGHT -->
<section id="insight">
  <h2 class="text-2xl font-bold text-[#003366] mb-2">
    InSight: AI-based retinal disease screening tool (June 2025)
  </h2>

  <ul class="list-disc list-inside space-y-2">
    <li>
      <strong>Developed InSight, an AI-based screening tool aimed at improving early detection of five major eye diseases</strong>
      — age-related macular degeneration, glaucoma, diabetic retinopathy, macular edema, and pathological myopia.
    </li>
    <li>
      These conditions collectively affect over 782 million people worldwide, yet access to screening remains limited in middle and low-income countries.
    </li>
    <li>
      Because many of these diseases are asymptomatic in their early stages, patients often miss the window for treatment. Currently, over 90% of the world’s blind population lives in lower-income regions.
    </li>
    <li>
      InSight integrates patient metadata with fundus images to enable accurate, real-time diagnosis through a three-stage pipeline:
      (1) Image Quality Assessment Model,
      (2) Multimodal Five-Disease Diagnosis Model,
      (3) Diabetic Retinopathy Severity Grading.
    </li>
    <li>
      The multitask model demonstrated strong generalizability across varied imaging conditions (lab-captured and mobile-captured fundus images) while detecting five diseases simultaneously.
    </li>
    <li>
      These results highlight InSight’s potential as a lightweight, accessible AI screening tool adaptable to both clinical and mobile-based applications.
    </li>
    <li>
      <strong>We presented our work on InSight and won first place at the county science fair, invited to the California Science & Engineering Fair (top 15 projects out of ~350 in Alameda County), and recognized with the “Outstanding AI Innovation” Award.</strong>
    </li>
    <li>[poster image]</li>
  </ul>

  <!-- Three poster images side by side -->
  <div class="flex flex-wrap justify-center items-center gap-4 mt-6">
    <img
      src="research_images/insight1.png"
      alt="InSight Poster 1"
      class="rounded-lg shadow-md border border-gray-200 w-full sm:w-[32%] md:w-[30%]"
    >
    <img
      src="research_images/insight2.png"
      alt="InSight Poster 2"
      class="rounded-lg shadow-md border border-gray-200 w-full sm:w-[32%] md:w-[30%]"
    >
    <img
      src="research_images/insight3.png"
      alt="InSight Poster 3"
      class="rounded-lg shadow-md border border-gray-200 w-full sm:w-[32%] md:w-[30%]"
    >
  </div>
</section>


    <section id="metafusion">
      <h2 class="text-2xl font-bold text-[#003366] mb-2">MetaFusion (Apr 2025)</h2>
      <p>Developed novel multimodal fusion method. Accepted for presentation at IEEE ISBI 2025.</p>
    </section>

    <section id="mediseeker">
      <h2 class="text-2xl font-bold text-[#003366] mb-2">Mediseeker (2024)</h2>
      <p>Developed three-stage drug discovery pipeline. Submitted to JHU Global Health Leaders Conference.</p>
    </section>

    <section id="tissueoforigin">
      <h2 class="text-2xl font-bold text-[#003366] mb-2">Tissue of Origin for CUP (2023)</h2>
      <p>AI-based tissue origin detection using miRNA. Published in Journal of Internet Medical Research.</p>
    </section>

    <section id="lendmeyourear">
      <h2 class="text-2xl font-bold text-[#003366] mb-2">Lend me your ear (2023)</h2>
      <p>Realtime speech enhancement and separation using Conv-TasNet. First Place Winner in County, State Honorable Mention.</p>
    </section>

    <section id="connectfour">
      <h2 class="text-2xl font-bold text-[#003366] mb-2">Connect Four (2022)</h2>
      <p>Reinforcement learning–based AI Player for Connect Four. Grand Sweepstakes in County Fair, 3rd place in state.</p>
    </section>

  </div>

</body>
</html>
